#!/bin/bash

# Matheus Fillipe --- 25/01/2022
# wcofun.com scraper MIT

##########################################################################################
# Things you might want to change:

# MENU_CMD. Choose your menu.
# NOTIFY_CMD. How to tell you about the status. Leave empty for a simple echo to stdout
 if [ -t 0 ] # if on a terminal
 then 
  MENU_CMD="fzf"
  NOTIFY_CMD=""
else
  MENU_CMD="rofi -dmenu -i"
  # MENU_CMD="dmenu"
  NOTIFY_CMD="notify-send WCOFUN"
 fi

# User agent. Maybe you have problems with this
UA="User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:96.0) Gecko/20100101 Firefox/96.0"

# Use system's curl if curl-impersonate is not found
for curl in \
  curl-impersonate \
  curl-impersonate-chrome \
  curl-impersonate-firefox \
  curl
do
    hash "$curl" &>/dev/null && break
done 
CURL_PATH="$curl"

# Maybe you want to use a proxy? (Helps when getting blocked by cloudflare, or if you want to debug)
CURL_EXTRA_PARAMS=""
# CURL_EXTRA_PARAMS="-k --tlsv1 -x http://localhost:8080"
PRE_COMMAND=""
# PRE_COMMAND="mitmdump 2>&1 /dev/null"


CONFIG_FILE=~/.wcofunrc 

##########################################################################################

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
WHITE='\033[1;37m'
BLUE='\033[0;34m'
BROWN='\033[0;33m'
PURPLE='\033[0;35m'
NC='\033[0m'

red()(set -o pipefail;"$@" 2>&1>&3|sed $'s,.*,\e[31m&\e[m,'>&2)3>&1

# if the config file exists, it will override the variables above
if [ -f ~/.wcofunrc ]
then
  echo "Loading config file ~/.wcofunrc"
  source "$CONFIG_FILE"
fi

if [ -z "$CURL_PATH" ]
then
   echo -e "${RED}Curl executable not found. You need to set CURL_PATH or install curl{$NC}"
  exit 1
fi

baseurl="https://www.wcofun.com/"
domainname="www.wcofun.com"

storage="$HOME/.local/share/wcofun.cli/"

get_cache () {
  if [ ! -f "$1" ]; then
    echo '{}' > "$1"
  fi
  cat "$1"
}

get_cache_search () {
  get_cache "$storage/search.json"
}

get_cache_episode () {
  get_cache "$storage/episode.json"
}

get_cache_series_url () {
  get_cache "$storage/series_url.json"
}

save_cache() {
  echo "$1" > "$2"
}

save_cache_search () {
  save_cache "$1" "$storage/search.json"
}

save_cache_episode () {
  save_cache "$1" "$storage/episode.json"
}

save_cache_series_url () {
  save_cache "$1" "$storage/series_url.json"
}


finalize (){
  [ -n "$PRE_COMMAND" ] && kill %1
  exit 0
}

mkdir -p "$storage"
touch "$storage/lastq"
trap finalize INT

menu_cmd () {
  case "$MENU_CMD" in
    "fzf"*)
      args=$(echo "$*" | sed -re 's/""(.+)""/"\1"/g')
      eval "$MENU_CMD $args"
      ;;
    "rofi"*)
      args=${*//--prompt/-p}
      args=${args//--query/-filter}
      args=$(echo "$args" | sed -re 's/""(.+)""/"\1"/g')
      eval "$MENU_CMD $args"
      ;;
    "dmenu"*)
      args=${*//--prompt/-p}
      args=${args//--print-query/}
      args=${args//--query \"*\"/}
      args=$(echo "$args" | sed -re 's/""(.+)""/"\1"/g')
      eval "$MENU_CMD $args"
      ;;
    *)
      echo "Warning: Unknown menu command: $MENU_CMD"
      eval "$MENU_CMD $*"
      ;;
  esac
}

notify_cmd () {
  echo "$*"
  if [ -n "$NOTIFY_CMD" ]; then
    $NOTIFY_CMD "$1"
  fi
}


chru() { printf "\x$(printf %x "$1")"; }

get_link() {
  link=$1
  script=$(
  "$CURL_PATH" --silent $CURL_EXTRA_PARAMS "$link" -H "$UA" --compressed | htmlq 'body > div:nth-child(3) > div.twelve.columns > div > div.fourteen.columns > div:nth-child(7) > script:nth-child(2)' | sed 's/<script>\(.*\)<\/script>/\1/')
  offset=$(echo "$script" | sed 's/.*- \([0-9]*\).*).*/\1/')

  innerscript=$(
  echo "$script" | cut -d "[" -f2 | cut -d "]" -f1 | tr "," "\n" | while read -r LINE; do
    n=$(echo "$LINE" | tr -d \" | base64 --decode | sed 's/[^[:digit:]]//g')
    n=$((n - offset))
    printf "%s" "$(chru $n)"
  done
  )

  url=$baseurl$(echo "$innerscript" | sed 's/^.*src="\([^"]*\)".*$/\1/')
  url=$baseurl$("$CURL_PATH" --silent $CURL_EXTRA_PARAMS "$url" -H "$UA" | grep "$.getJSON" | sed 's/^.*"\(.*\)".*$/\1/')

  "$CURL_PATH" --silent $CURL_EXTRA_PARAMS  "$url" \
    -H "authority: $domainname" \
    -H 'pragma: no-cache' \
    -H 'cache-control: no-cache' \
    -H 'accept: application/json, text/javascript, */*; q=0.01' \
    -H "$UA" \
    -H 'x-requested-with: XMLHttpRequest' \
    -H 'sec-gpc: 1' \
    -H 'sec-fetch-site: same-origin' \
    -H 'sec-fetch-mode: cors' \
    -H 'sec-fetch-dest: empty' \
    -H "Referer: $baseurl" \
    -H 'accept-language: en-US,en;q=0.9' \
    --compressed | jq -r '(.cdn + "/getvid?evid=" + .enc)'
}

get_num() {
  echo "$1" | sed -re 's/^"*([[:digit:]]+)>.*$/\1/g'
}

download () {
  "$CURL_PATH" "$1" \
    -H 'Connection: keep-alive' \
    -H "$UA" \
    -H 'Accept: */*' \
    -H 'Sec-GPC: 1' \
    -H 'Sec-Fetch-Site: cross-site' \
    -H 'Sec-Fetch-Mode: no-cors' \
    -H 'Sec-Fetch-Dest: video' \
    -H "Referer: $baseurl" \
    -H 'Accept-Language: en-US,en;q=0.9' \
    -H 'Range: bytes=0-' \
    --compressed --output "$2"
  if [ $? -ne 0 ]; then
    notify_cmd "Error: failed to get video"
  fi
}

stream () {
  "$CURL_PATH" "$1" \
    -H 'Connection: keep-alive' \
    -H "$UA" \
    -H 'Accept: */*' \
    -H 'Sec-GPC: 1' \
    -H 'Sec-Fetch-Site: cross-site' \
    -H 'Sec-Fetch-Mode: no-cors' \
    -H 'Sec-Fetch-Dest: video' \
    -H "Referer: $baseurl" \
    -H 'Accept-Language: en-US,en;q=0.9' \
    -H 'Range: bytes=0-' \
    --compressed | mpv -
  if [ $? -ne 0 ]; then
    notify_cmd "Error: failed to get video"
  fi
}

search () {
  list=$(
    "$CURL_PATH" --silent $CURL_EXTRA_PARAMS "$baseurl/search" \
    -X POST -H "$UA" \
    -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8' \
    -H 'Accept-Language: en-US,en;q=0.5' \
    -H 'Accept-Encoding: gzip, deflate' \
    -H 'Content-Type: application/x-www-form-urlencoded' \
    -H "Origin: $baseurl" \
    -H 'Connection: keep-alive' \
    -H "Referer: $baseurl/search" \
    -H 'Upgrade-Insecure-Requests: 1' \
    -H 'Sec-Fetch-Dest: document' \
    -H 'Sec-Fetch-Mode: navigate' \
    -H 'Sec-Fetch-Site: same-origin' \
    -H 'Sec-Fetch-User: ?1' \
    -H 'Pragma: no-cache' \
    -H 'Cache-Control: no-cache' \
    -H 'TE: trailers' \
    --data-raw "catara=${1// /+}&konuara=series" \
    --compressed | htmlq "div.img"
  )
  titles=$(echo "$list" | htmlq 'img' -a alt)
 
  if [ -z "$titles" ]; then
    exit 1
  fi

  anime=${1//-/_}
  lastq="$(get_cache_search | jq '.'"${anime// /_}"'')"
  if [ "$lastq" == "null" ]; then
    choosen=$(echo "$titles" | awk '{print NR  "> " $0}' | menu_cmd) 
  else
    choosen=$(echo "$titles" | awk '{print NR  "> " $0}' | menu_cmd --query \""$lastq"\" )
  fi

  if [ -z "$choosen" ]; then
    return
  fi

  save_cache_search "$(get_cache_search | jq '.'"${anime// /_}"' = "'"$choosen"'"')"
  n=$(get_num "$choosen")
  anime=$(echo "$list" | htmlq 'a' -a href | awk 'NR=='"$n")
  save_cache_series_url "$(get_cache_series_url | jq '.'"${query// /_}"' = "'"$anime"'"')"
  echo "$anime"
}

choose_ep () {
  offset=$2
  list=$("$CURL_PATH" --silent $CURL_EXTRA_PARAMS "$1" \
  -H "authority: $domainname" \
  -H 'pragma: no-cache' \
  -H 'cache-control: no-cache' \
  -H 'upgrade-insecure-requests: 1' \
  -H "$UA" \
  -H 'accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9' \
  -H 'sec-gpc: 1' \
  -H 'sec-fetch-site: none' \
  -H 'sec-fetch-mode: navigate' \
  -H 'sec-fetch-user: ?1' \
  -H 'sec-fetch-dest: document' \
  -H 'accept-language: en-US,en;q=0.9' \
  --compressed | htmlq '#sidebar_right3 a' | tac)
  titles=$(echo "$list" | htmlq 'a' -a title)

  if [ -z "$titles" ]; then
    exit 1
  fi

  choosen_anime=${1##*/}
  choosen_anime=${choosen_anime//-/_}
  lastq="$(get_cache_episode | jq '.'"$choosen_anime"'')"
  if [ "$lastq" == "null" ]; then
    choosen=$(echo "$titles" | awk '{print NR  "> " $0}' | menu_cmd) 
  else
    n=$(get_num "$lastq")
    if [ -n "$offset" ]; then
      n=$((n + offset))
      choosen="$n> $(echo "$titles" | sed "${n}q;d")"
    else
      choosen=$(echo "$titles" | awk '{print NR  "> " $0}' | menu_cmd --query \""$n>"\" )
    fi
  fi

  if [ -z "$choosen" ]; then
    return
  fi

  save_cache_episode "$(get_cache_episode | jq '.'"$choosen_anime"' = "'"$choosen"'"')"
  n=$(get_num "$choosen")
  echo "$list" | htmlq 'a' -a href | awk 'NR=='"$n"
  echo "$n"
}

all_eps () {
  "$CURL_PATH" --silent $CURL_EXTRA_PARAMS "$1" \
  -H "authority: $domainname" \
  -H 'pragma: no-cache' \
  -H 'cache-control: no-cache' \
  -H 'upgrade-insecure-requests: 1' \
  -H "$UA" \
  -H 'accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9' \
  -H 'sec-gpc: 1' \
  -H 'sec-fetch-site: none' \
  -H 'sec-fetch-mode: navigate' \
  -H 'sec-fetch-user: ?1' \
  -H 'sec-fetch-dest: document' \
  -H 'accept-language: en-US,en;q=0.9' \
  --compressed | htmlq '#sidebar_right3 a ' | tac
}

download_many () {
  query=$1
  anime=$2
  download_range=$3

  folder="${query// /_}"
  mkdir -p "$folder"
  eps=$(all_eps "$anime")
  if [ -n "$download_range" ]; then
    start=${download_range/-*/}
    end=${download_range/*-/}
    if [ -z "$end" ]; then
      end=$(echo "$eps" | wc -l)
    fi
    if [ -z "$start" ]; then
      start=1
    fi
    re='^[0-9]+$'
    if ! [[ $start =~ $re ]] ; then
       echo -e "${RED}Invalid range! \"$start\" Not a number ${NC}" >&2; 
       exit 1
    fi
    if ! [[ $end =~ $re ]] ; then
       echo -e "${RED}Invalid range! \"$end\" Not a number ${NC}" >&2; 
       exit 1
    fi
    notify_cmd "Downloading from episode $start to $end into: $folder"
  else
    start=1
    end=$(echo "$eps" | wc -l)
    notify_cmd "Downloading all episodes to: $folder"
  fi
  counter=0
  echo 
  echo
  echo "$eps" | while read -r line; do
    counter=$((counter+1))
    if [ $counter -lt "$start" ]; then
      continue
    fi
    if [ $counter -gt "$end" ]; then
      break
    fi
    ep=$(echo "$line" | htmlq 'a' -a href)
    title=$(echo "$line" | htmlq 'a' -a title)
    echo "Downloading: $title"
    echo "Episode url: $ep"
    url=$(get_link "$ep")
    echo "Got link: $url"
    download "$url" "$folder/$title.mp4"
  done
}

help() {
   echo 
   echo -e "                     ${GREEN}WCOFUN.CLI${NC}"
   echo -e "${BLUE}---------------------------------------------------------------------------------${NC}"
   echo -e "${PURPLE}Syntax: ${NC}"
   echo -e "  ${WHITE}$0${NC} [-n] [${BROWN}-s${NC} | ${BLUE}-D${NC} | ${RED}-d [range]${NC}] ${GREEN}[search query]${NC}"
   echo -e "  All parameters are optional."
   echo
   echo -e "${PURPLE}Example: ${NC}"
   echo -e "  Search and stream or download one episode: wcofun ${GREEN}[search query]${NC}"
   echo -e "  Download all episodes: wcofun -D ${GREEN}[search query]${NC}"
   echo -e "  Watch next episode: wcofun -n"
   echo
   echo -e "${PURPLE}Options: ${NC}"
   echo -e "  ${GREEN}-D:${NC} Download all episodes of selected anime."
   echo -e "  ${GREEN}-d [ep-number|start-end]:${NC} Download a range of episodes by specifying the beginning and end. You can also specify a single episode number or a range like n- to download all starting from the nth or -n to download all until the nth. An empty range (-) will cause cause it to prompt for the episode number and then download."
   echo -e "  ${GREEN}-s:${NC} Stream selectped episode"
   echo -e "  ${GREEN}-n:${NC} Play next episode of lastly watched anime"
   echo -e "  ${GREEN}-p:${NC} Play previous episode of lastly watched anime"
   echo -e "  ${GREEN}-P [command]:${NC} Pre execution command. Useful for launching an http proxy."
   echo -e "  ${GREEN}-e:${NC} Edit config with $EDITOR"
   echo -e "  ${GREEN}-c:${NC} Edit cached searches with $EDITOR"
   echo -e "  ${GREEN}-h:${NC} Show this help"
   echo
}

parse_opts () {
  download=false
  stream_ep=false
  next_ep=false
  previous_ep=false
  download_range=""

  while getopts "hP:d:Dsecnp" o; do
      case "${o}" in
          \?)
              echo -e "${RED}Invalid option or missing argument: $OPTARG${NC}"
              echo
              help
              exit 1
              ;;
          h)
              help
              exit 0
              ;;
          d)
            download_range=${OPTARG}
            if [ "$download_range" == "-" ]; then
              download=false
            else
              download=true
            fi
            ;;
          s)
            stream_ep=true
            ;;
          e)
            $EDITOR $CONFIG_FILE
            exit 0
            ;;
          c)
            $EDITOR "$storage/lastq"
            exit 0
            ;;
          n)
            next_ep=true
            ;;
          p)
            previous_ep=true
            ;;
          D)
            download=true
          ;;
          P)
              PRE_COMMAND=${OPTARG}
              ;;
          *)
            ;;
      esac
  done

  if [[ $next_ep = true && $previous_ep = true ]]; then
    echo -e "${RED}You should either watch the next or the previous episode${NC}" >&2
    exit 1
  fi
  if [[ $download = true && $stream_ep = true ]]; then
    echo -e "${RED}You should either download or stream${NC}" >&2
    exit 1
  fi

  shift $((OPTIND - 1))
  query="$@"
}

main () {
  parse_opts "$@"

  if [ -n "$PRE_COMMAND" ]
  then
    echo "Launching: $PRE_COMMAND"
    eval "$PRE_COMMAND &"
    # Bad hack but....
    sleep 3
  fi

  if [[ "$next_ep" = true || "$previous_ep" = true ]]; then
    query_file="$storage/lastq"
    lastq=$(head -n 1 "$query_file")
    query=${lastq//-/_}
    anime="$(get_cache_series_url | jq '.'"${query// /_}"'')"
    anime=${anime//\"/}
  else
    query_file="$storage/lastq"
    if [ -z "$query" ]; then
      lastq=$(head -n 1 "$query_file")
      if [ -z "$lastq" ]; then
        query=$(cat "$query_file" 2>/dev/null | menu_cmd --prompt \"Search query: \" --print-query | head -1)
      else
        query=$(cat "$query_file" 2>/dev/null | menu_cmd --prompt \"Search query: \" --query \""$lastq"\" --print-query | head -1)
      fi
    fi
    currentq=$(printf '%s\n%s' "$query" "$(cat "$query_file" 2>/dev/null)")
    echo "$currentq" | sed -re '/^[[:space:]]*$/d' >> "$query_file.tmp"
    awk '!x[$0]++' "$query_file.tmp" > "$query_file"
    rm "$query_file.tmp"
    echo "Searching for: $query"

    anime=$(search "$query")
    if [ -z "$anime" ]; then
      notify_cmd "No results for: $query"
      [ -n "$PRE_COMMAND" ] && kill %1
      exit 1
    fi
  fi
  echo "Selected anime: $anime"


  # Download episodes range
  if [ "$download" = true ]; then
    download_many "$query" "$anime" "$download_range"
    [ -n "$PRE_COMMAND" ] && kill %1
    notify_cmd "Download finished: $folder"
    exit 0
  fi

  if [[ "$next_ep" = true ]]; then
    ep=$(choose_ep "$anime" 1)
  elif [[ "$previous_ep" = true ]]; then
    ep=$(choose_ep "$anime" -1)
  else
    ep=$(choose_ep "$anime")
  fi
  n=$(echo "$ep" | sed "2q;d")
  ep=$(echo "$ep" | sed "1q;d")

  if [ -z "$ep" ]; then
    [ -n "$PRE_COMMAND" ] && kill %1
    exit 1
  fi
  echo "Selected episode: $ep"

  if [ "$stream_ep" = true ]; then
    opt="Stream"
  elif [ -n "$download_range" ]; then
    opt="Download"
  else
    opt=$(printf "%s\n%s" "Stream" "Download" | menu_cmd)
  fi
  notify_cmd "Fetching video url..."
  url=$(get_link "$ep")
  echo "Got url: $url"

  [ -n "$PRE_COMMAND" ] && kill %1
  case $opt in
    Stream)
      notify_cmd "Starting stream of episode $n"
      stream "$url"
      ;;
    Download)
      filename=$(echo " " | menu_cmd --prompt \"Save Path: \" --query \""${ep##*/}.mp4"\" --print-query)
      if [ -z "$filename" ]; then
        notify_cmd "Canceled."
        exit 0
      fi
      notify_cmd "Downloading episode $n to: $filename"
      download "$url" "$filename"
      notify_cmd "Download finished: $filename"
      ;;
  esac
}

main "$@"
